{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniProj3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44147ade4f604f99a6cafea382d987d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30236ae7d2224274a561999c2e154f3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_791e721cef1445ee9921c4ecea77778e",
              "IPY_MODEL_63ff5b2c5c694a0096c4b698596b3d51"
            ]
          }
        },
        "30236ae7d2224274a561999c2e154f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "791e721cef1445ee9921c4ecea77778e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c330b1df73447e488d4891aafdaf63b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61031b3db90e460c8cd282b5f90112b5"
          }
        },
        "63ff5b2c5c694a0096c4b698596b3d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c1d0c85d8484186a28315897509a6ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:06&lt;00:00, 27799631.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fb7b6b6083246f7a30405eee7ed7837"
          }
        },
        "0c330b1df73447e488d4891aafdaf63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61031b3db90e460c8cd282b5f90112b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c1d0c85d8484186a28315897509a6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fb7b6b6083246f7a30405eee7ed7837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WoGDhI8KqwT",
        "colab_type": "text"
      },
      "source": [
        "# **MLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHbuvvTuKxW4",
        "colab_type": "text"
      },
      "source": [
        "For MLP, we implemented 1-hidden layer MLP and 2-hidden layer MLP. We tried gradient descent, SGD, and SGD with momentum. For the activation function, we tried sigmoid, RELU, and leaky RELU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89JvvNqIKcCp",
        "colab_type": "text"
      },
      "source": [
        "## 1-hidden layer MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mBqAkuqKky3",
        "colab_type": "code",
        "outputId": "12bbfe75-e020-47a6-9cc6-ef3c2c781f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from keras.datasets import cifar10\n",
        "import time\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "    \n",
        "\n",
        "file_prefix = \"./data/cifar-10-batches-py/\"\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in range(1,6):\n",
        "    file_name = file_prefix + \"data_batch_\" + str(i)\n",
        "    f = unpickle(file_name)\n",
        "    x.append(f[b'data'])       # a 10000x3072 numpy array of uint8\n",
        "    y.append(np.array(f[b'labels']))    # a list of 10000 numbers in the range 0-9\n",
        "    xtemp = f[b'data']\n",
        "    ytemp = np.array(f[b'labels']).reshape(10000,-1)\n",
        "\n",
        "x = np.array(x).reshape(50000, -1)\n",
        "\n",
        "x_train = x\n",
        "y = np.array(y).reshape(50000, -1)\n",
        "\n",
        "\n",
        "one_hot_labels = np.zeros((50000, 10))\n",
        "\n",
        "for i in range(50000):\n",
        "    one_hot_labels[i, y[i]] = 1\n",
        "\n",
        "\n",
        "# load test data \n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "file_name = file_prefix + \"test_batch\"\n",
        "f = unpickle(file_name)\n",
        "x_test.append(f[b'data'])       # a 10000x3072 numpy array of uint8\n",
        "y_test.append(np.array(f[b'labels']))    # a list of 10000 numbers in the range 0-9\n",
        "\n",
        "x_test = np.array(x_test).reshape(10000, -1)\n",
        "y_test = np.array(y_test).reshape(10000, -1)\n",
        "\n",
        "\n",
        "def sigmoid(s):\n",
        "    return 1/(1 + np.exp(-s))\n",
        "\n",
        "\n",
        "def sigmoid_derv(s):\n",
        "    return s * (1 - s)\n",
        "\n",
        "\n",
        "def relu(X): \n",
        "    return np.maximum(X, 0)\n",
        "\n",
        "\n",
        "def relu_der(X):\n",
        "    indices = X > 0\n",
        "    result = np.zeros(X.shape)\n",
        "    result[indices] = 1\n",
        "    return result\n",
        "\n",
        "def leakyrelu(x1, alpha=0.01):\n",
        "\t  return np.maximum(x1, x1 * 0.01)\n",
        "   \n",
        "def leakyrelu_der(X, alpha=0.01):\n",
        "    indices = X < 0\n",
        "    result = np.ones(X.shape)\n",
        "    result[indices] = 0.01\n",
        "    return result\n",
        "\n",
        "def softmax(s):\n",
        "    exps = np.exp(s - np.max(s, axis=1, keepdims=True))\n",
        "    return exps/np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def cross_entropy(p, r):\n",
        "    n = r.shape[0]\n",
        "    ce_sum = p - r\n",
        "    ce = ce_sum/n\n",
        "    return ce\n",
        "    \n",
        "\n",
        "def error(p, r):\n",
        "    n = r.shape[0]\n",
        "    erri = - np.log(p[np.arange(n), r.argmax(axis=1)])\n",
        "    err = np.sum(erri)/n\n",
        "    return err\n",
        "\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, x, y):\n",
        "        # sgd\n",
        "        batch = np.random.randint(0, x.shape[0], (4))\n",
        "        self.x = x[batch, :]\n",
        "        self.y = y[batch, :]\n",
        "        print(self.x.shape, \" ,\", self.y.shape)\n",
        "        h = 128\n",
        "        self.lr = 0.0001\n",
        "        x1 = x.shape[1]\n",
        "        y1 = y.shape[1]\n",
        "        self.n = x.shape[0]\n",
        "\n",
        "        self.w1 = np.random.randn(x1, h)*.01\n",
        "        self.b1 = np.ones((1, h))\n",
        "        self.w2 = np.random.randn(h, y1)*.01\n",
        "        self.b2 = np.ones((1, y1))\n",
        "\n",
        "        self.z1 = np.zeros((self.n, h))\n",
        "        self.z2 = np.zeros((self.n, y1))\n",
        "        self.dw2 = np.zeros((h, y1))\n",
        "        self.dw1 = np.zeros((x1, h))\n",
        " \n",
        "\n",
        "    def forward(self):\n",
        "        self.z1 = np.dot(self.x, self.w1) + self.b1  # n, 128\n",
        "        self.a1 = relu(self.z1)                 \n",
        "        self.z2 = np.dot(self.a1, self.w2) + self.b2 # n, 10\n",
        "        self.a2 = softmax(self.z2)\n",
        "        \n",
        "    def back(self):\n",
        "        # #-----------------sgd-----------------\n",
        "        # da2 = cross_entropy(self.a2, self.y)\n",
        "        # dz2 = da2 # n, 10\n",
        "        # self.dw2 = 0.99 * np.dot(self.a1.T, dz2) + 0.01 * self.dw2 # 128, 10\n",
        "        # da1 = np.dot(dz2, self.w2.T)    # n, 128\n",
        "        # dz1 = da1 * relu_der(self.z1)     # n, 128\n",
        "        # self.dw1 = 0.9 * np.dot(self.x.T, dz1) + 0.1 * self.dw1  # 10, 128\n",
        "        # self.w2 -= self.lr * self.dw2\n",
        "        # self.w1 -= self.lr * self.dw1\n",
        "        #-----------------momentum-----------------\n",
        "        da2 = cross_entropy(self.a2, self.y)\n",
        "        dz2 = da2 # n, 10\n",
        "        self.dw2 = 0.9 * np.dot(self.a1.T, dz2) + 0.1 * self.dw2 # 128, 10\n",
        "        da1 = np.dot(dz2, self.w2.T)    # n, 128\n",
        "        dz1 = da1 * relu_der(self.z1)     # n, 128\n",
        "        self.dw1 = 0.9 * np.dot(self.x.T, dz1) + 0.1 * self.dw1  # 10, 128\n",
        "        self.w2 -= self.lr * self.dw2\n",
        "        self.w1 -= self.lr * self.dw1\n",
        "\n",
        "    def predict(self, data):\n",
        "        self.x = data\n",
        "        self.forward()\n",
        "        return self.a2\n",
        "\t\t\t\n",
        "model = MLP(x_train, one_hot_labels)\n",
        "epochs = 10000\n",
        "result = []\n",
        "t1= time.time()\n",
        "for i in range(epochs):\n",
        "    # sgd\n",
        "    batch = np.random.randint(0, x_train.shape[0], (100))\n",
        "    model.x = x_train[batch, :]\n",
        "    model.y = one_hot_labels[batch, :]\n",
        "    model.forward()\n",
        "    model.back()\n",
        "    if i%500 == 0:\n",
        "      r = error(model.predict(model.x), model.y)\n",
        "      np.append(result,[r])\n",
        "      print(\"error:\", r)\n",
        "# print(r)\n",
        "# rshape = r.shape\n",
        "# plt.plot(rshape,r)\n",
        "# plt.xlabel('1000 epochs')\n",
        "# plt.ylabel('cross entropy')\n",
        "acc = 0\n",
        "for a,b in zip(x_train, y):\n",
        "  s = model.predict(a)\n",
        "  if b == (np.argmax(s)):\n",
        "    acc +=1\n",
        "accuracy= acc/len(x_train)*100\n",
        "print(\"Training accuracy : \", accuracy)\n",
        "print(\"--- %s seconds ---\" % (time.time() - t1))\n",
        "acc = 0\n",
        "for a,b in zip(x_test, y_test):\n",
        "  s = model.predict(a)\n",
        "  if b == (np.argmax(s)):\n",
        "    acc +=1\n",
        "accuracy= acc/len(x_test)*100\n",
        "print(\"Test accuracy : \", accuracy)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(4, 3072)  , (4, 10)\n",
            "error: 9.818321920446074\n",
            "error: 1.8166134035889288\n",
            "error: 1.6264867275715362\n",
            "error: 1.4582638996375976\n",
            "error: 1.7389891013493222\n",
            "error: 1.6965588714770672\n",
            "error: 1.472014028525277\n",
            "error: 1.8449620727715907\n",
            "error: 1.4833901356284362\n",
            "error: 1.6086799432157395\n",
            "error: 1.4291353303877548\n",
            "error: 1.5600784745067475\n",
            "error: 1.5707721267916626\n",
            "error: 1.5526311594291562\n",
            "error: 1.3598931228722035\n",
            "error: 1.5512372251399404\n",
            "error: 1.3813275712226052\n",
            "error: 1.4672183327547428\n",
            "error: 1.3161742260856086\n",
            "error: 1.4997509810858107\n",
            "Training accuracy :  47.75\n",
            "--- 126.64086627960205 seconds ---\n",
            "Test accuracy :  45.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnhLyLaGKSs2",
        "colab_type": "text"
      },
      "source": [
        "## 2-hidden layer MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWrt9uRdLOYj",
        "colab_type": "code",
        "outputId": "e59cad4d-ff03-413f-d2a9-fb6aad8aae7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "    \n",
        "\n",
        "file_prefix = \"./data/cifar-10-batches-py/\"\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in range(1,6):\n",
        "    file_name = file_prefix + \"data_batch_\" + str(i)\n",
        "    f = unpickle(file_name)\n",
        "    x.append(f[b'data'])       # a 10000x3072 numpy array of uint8\n",
        "    y.append(np.array(f[b'labels']))    # a list of 10000 numbers in the range 0-9\n",
        "    xtemp = f[b'data']\n",
        "    ytemp = np.array(f[b'labels']).reshape(10000,-1)\n",
        "\n",
        "x = np.array(x).reshape(50000, -1)\n",
        "\n",
        "x_train = x\n",
        "y = np.array(y).reshape(50000, -1)\n",
        "\n",
        "\n",
        "one_hot_labels = np.zeros((50000, 10))\n",
        "\n",
        "for i in range(50000):\n",
        "    one_hot_labels[i, y[i]] = 1\n",
        "\n",
        "\n",
        "# load test data \n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "file_name = file_prefix + \"test_batch\"\n",
        "f = unpickle(file_name)\n",
        "x_test.append(f[b'data'])       # a 10000x3072 numpy array of uint8\n",
        "y_test.append(np.array(f[b'labels']))    # a list of 10000 numbers in the range 0-9\n",
        "\n",
        "x_test = np.array(x_test).reshape(10000, -1)\n",
        "y_test = np.array(y_test).reshape(10000, -1)\n",
        "\n",
        "\n",
        "def sigmoid(s):\n",
        "    return 1/(1 + np.exp(-s))\n",
        "\n",
        "\n",
        "def sigmoid_derv(s):\n",
        "    return s * (1 - s)\n",
        "\n",
        "\n",
        "def relu(X): \n",
        "    return np.maximum(X, 0)\n",
        "\n",
        "\n",
        "def relu_der(X):\n",
        "    indices = X > 0\n",
        "    result = np.zeros(X.shape)\n",
        "    result[indices] = 1\n",
        "    return result\n",
        "\n",
        "\n",
        "def softmax(s):\n",
        "    exps = np.exp(s - np.max(s, axis=1, keepdims=True))\n",
        "    return exps/np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def cross_entropy(p, r):\n",
        "    n = r.shape[0]\n",
        "    ce_sum = p - r\n",
        "    ce = ce_sum/n\n",
        "    return ce\n",
        "    \n",
        "\n",
        "def error(p, r):\n",
        "    n = r.shape[0]\n",
        "    erri = - np.log(p[np.arange(n), r.argmax(axis=1)])\n",
        "    err = np.sum(erri)/n\n",
        "    return err\n",
        "\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, x, y):\n",
        "        # sgd\n",
        "        batch = np.random.randint(0, x.shape[0], (4))\n",
        "        self.x = x[batch, :]\n",
        "        self.y = y[batch, :]\n",
        "        print(self.x.shape, \" ,\", self.y.shape)\n",
        "        h = 128\n",
        "        self.lr = 0.0001\n",
        "        x1 = x.shape[1]\n",
        "        y1 = y.shape[1]\n",
        "        self.n = x.shape[0]\n",
        "\n",
        "        self.w1 = np.random.randn(x1, h)*.01\n",
        "        self.b1 = np.ones((1, h))\n",
        "        self.w2 = np.random.randn(h, h)*.01\n",
        "        self.b2 = np.ones((1, h))\n",
        "        self.w3 = np.random.randn(h, y1)*.01\n",
        "        self.b3 = np.ones((1, y1))\n",
        "\n",
        "        self.z1 = np.zeros((self.n, h))\n",
        "        self.z2 = np.zeros((self.n, h))\n",
        "        self.z3 = np.zeros((self.n, y1))\n",
        "        self.dw3 = np.zeros((h, y1))\n",
        "        self.dw2 = np.zeros((h, h))\n",
        "        self.dw1 = np.zeros((x1, h))\n",
        " \n",
        "\n",
        "    def forward(self):\n",
        "        self.z1 = np.dot(self.x, self.w1) + self.b1  # n, 128\n",
        "        self.a1 = relu(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.w2) + self.b2 # n, 128\n",
        "        self.a2 = relu(self.z2)                   \n",
        "        self.z3 = np.dot(self.a2, self.w3) + self.b3 # n, 10\n",
        "        self.a3 = softmax(self.z3)\n",
        "        \n",
        "    def back(self):\n",
        "        # loss = error(self.a3, self.y)\n",
        "        # print('Error :', loss)\n",
        "        # da3 = cross_entropy(self.a3, self.y)\n",
        "        # dz2 = da3 * self.w3\n",
        "        # print(dz2.shape)\n",
        "        # da2 = dz2 * sigmoid_derv(self.a2)\n",
        "        # dz1 = np.dot(da2, self.w2.T)\n",
        "        # print(dz1.shape)\n",
        "        # da1 = dz1 * sigmoid_derv(self.a1) \n",
        "        #sgd\n",
        "        # self.w3 -= self.lr * da3\n",
        "        # self.b3 -= self.lr * np.sum(da3, axis=0, keepdims=True)\n",
        "        # self.w2 -= self.lr * da2\n",
        "        # self.b2 -= self.lr * np.sum(da2, axis=0)\n",
        "        # self.w1 -= self.lr * da1\n",
        "        # self.b1 -= self.lr * np.sum(da1, axis=0)\n",
        "\n",
        "        # sigmoid\n",
        "        # da3 = cross_entropy(self.a3, self.y)\n",
        "        # dz3 = da3 # n, 10\n",
        "        # dw3 = np.dot(self.a2.T, dz3) # 128, 10\n",
        "        # da2 = np.dot(dz3, self.w3.T)   # n, 128\n",
        "        # dz2 = da2 * sigmoid_derv(self.a2)               # n, 128\n",
        "        # dw2 = np.dot(self.a1.T, dz2)  # 128, 128\n",
        "        # da1 = np.dot(dz2, self.w2.T)    # n, 128\n",
        "        # dz1 = da1 * sigmoid_derv(self.a1)     # n, 128\n",
        "        # dw1 = np.dot(self.x.T, dz1)   # 10, 128\n",
        "\n",
        "        # self.w3 -= self.lr * dw3\n",
        "        # self.w2 -= self.lr * dw2\n",
        "        # self.w1 -= self.lr * dw1\n",
        "\n",
        "        # relu with momentum\n",
        "        da3 = cross_entropy(self.a3, self.y)\n",
        "        dz3 = da3 # n, 10\n",
        "        self.dw3 = 0.9 * np.dot(self.a2.T, dz3)+ 0.1 * self.dw3 # 128, 10\n",
        "        da2 = np.dot(dz3, self.w3.T)   # n, 128\n",
        "        dz2 = da2 * relu_der(self.z2)  # n, 128\n",
        "        self.dw2 = 0.9 * np.dot(self.a1.T, dz2) + 0.1 * self.dw2 # 128, 128\n",
        "        da1 = np.dot(dz2, self.w2.T)    # n, 128\n",
        "        dz1 = da1 * relu_der(self.z1)     # n, 128\n",
        "        self.dw1 = 0.9 * np.dot(self.x.T, dz1) + 0.1 * self.dw1  # 10, 128\n",
        "\n",
        "        self.w3 -= self.lr * self.dw3\n",
        "        self.w2 -= self.lr * self.dw2\n",
        "        self.w1 -= self.lr * self.dw1\n",
        "\n",
        "    def predict(self, data):\n",
        "        self.x = data\n",
        "        self.forward()\n",
        "        return self.a3\n",
        "\t\t\t\n",
        "model = MLP(x_train, one_hot_labels)\n",
        "epochs = 10000\n",
        "for i in range(epochs):\n",
        "    # sgd\n",
        "    batch = np.random.randint(0, x_train.shape[0], (100))\n",
        "    model.x = x_train[batch, :]\n",
        "    model.y = one_hot_labels[batch, :]\n",
        "    model.forward()\n",
        "    model.back()\n",
        "    if i%500 == 0:\n",
        "      print(\"error:\", error(model.predict(model.x), model.y))\n",
        "\n",
        "acc = 0\n",
        "for a,b in zip(x_train, y):\n",
        "  s = model.predict(a)\n",
        "  if b == (np.argmax(s)):\n",
        "    acc +=1\n",
        "accuracy= acc/len(x_train)*100\n",
        "print(\"Training accuracy : \", accuracy)\n",
        "\n",
        "acc = 0\n",
        "for a,b in zip(x_test, y_test):\n",
        "  s = model.predict(a)\n",
        "  if b == (np.argmax(s)):\n",
        "    acc +=1\n",
        "accuracy= acc/len(x_test)*100\n",
        "print(\"Test accuracy : \", accuracy)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(4, 3072)  , (4, 10)\n",
            "error: 2.5123145421757496\n",
            "error: 2.092376002518807\n",
            "error: 1.941127259718173\n",
            "error: 1.9013863675043856\n",
            "error: 1.7471512431918055\n",
            "error: 1.8132510347431015\n",
            "error: 1.8328592252534464\n",
            "error: 1.7672804536879556\n",
            "error: 1.6195832113499566\n",
            "error: 1.8634109086605977\n",
            "error: 1.627617040804861\n",
            "error: 1.769414949793371\n",
            "error: 1.5285215432826815\n",
            "error: 1.7019927284164569\n",
            "error: 1.639803308372466\n",
            "error: 1.912969667915001\n",
            "error: 1.5813896592126773\n",
            "error: 1.4605009586385116\n",
            "error: 1.5768545860199115\n",
            "error: 1.4710605251662252\n",
            "Training accuracy :  43.256\n",
            "Test accuracy :  42.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_hp5nmpL0KJ",
        "colab_type": "text"
      },
      "source": [
        "**Cross entropy plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCObJ4z3L4lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "        path = \"/content/d2.txt\"\n",
        "        X = np.array([])\n",
        "        with open(path, \"r\") as f:\n",
        "            for line in f:\n",
        "                instance = np.array(line.split(\":\"))\n",
        "                if X.size == 0:\n",
        "                    X = np.array([instance])\n",
        "                else:\n",
        "                    X = np.append(X, [instance])\n",
        "            np.reshape(X,(20,2))\n",
        "            print(X[1])\n",
        "            Y=np.array([])\n",
        "            for i in range(40):\n",
        "                \n",
        "                if i%2 == 1:\n",
        "                    Y = np.append(Y, [X[i]])\n",
        "            print(Y)\n",
        "            Y.reshape(20,1)\n",
        "            j=0\n",
        "            while j<20:\n",
        "              Y[j] = Y[j].replace(\"\\n\", \"\")\n",
        "              Y[j] = float(Y[j])\n",
        "              j = j+1\n",
        "            Y=Y.astype(np.float)\n",
        "            print(type(Y[1]))\n",
        "            print(Y)\n",
        "            b = range(1, 21)\n",
        "            plt.plot(b, Y)\n",
        "            plt.xlabel('number of epochs/ 250 epochs')\n",
        "            plt.ylabel('cross entropy')\n",
        "            plt.savefig(\"fig1.png\")\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6QqcjaMWhPi",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2SzBhU6ZCHq",
        "colab_type": "text"
      },
      "source": [
        "##Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSHju4ZcWjsJ",
        "colab_type": "code",
        "outputId": "24462608-bfdd-4b30-ed48-04195ff2f812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "44147ade4f604f99a6cafea382d987d3",
            "30236ae7d2224274a561999c2e154f3b",
            "791e721cef1445ee9921c4ecea77778e",
            "63ff5b2c5c694a0096c4b698596b3d51",
            "0c330b1df73447e488d4891aafdaf63b",
            "61031b3db90e460c8cd282b5f90112b5",
            "5c1d0c85d8484186a28315897509a6ec",
            "8fb7b6b6083246f7a30405eee7ed7837"
          ]
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# compose two transformer into one\n",
        "# transform.ToTensor() convert PIL image to Tensor objects\n",
        "# transform.Normalize() normalizes each channel with mean 0.5 and std 0.5, so all the data will be in the range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# download the training set with the composed transformer\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "# create a dataloader for training set. The batch size is 4 and there are 2 workers that can generate data parallely. \n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "# dowload the test set with the composed transformer\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "# create a dataloader for training set. The batch size is 4 and there are 2 workers that can generate data parallely.\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44147ade4f604f99a6cafea382d987d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D9akEnVoaOY",
        "colab_type": "text"
      },
      "source": [
        "## Define the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYYsIx_BodAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # define the convolutional layer 1\n",
        "        # filter dimension: 5, 5, 1\n",
        "        # stride: 1\n",
        "        # padding: no padding (valid form)\n",
        "        # input contains 3 channels and the output has 20\n",
        "        self.conv1 = nn.Conv2d(3, 20, 5)\n",
        "\n",
        "        # define the pool layer\n",
        "        # pooling filter dimension: 2, 2, 1 \n",
        "        # stride: 2\n",
        "        # output dimension: ((28 - 2)/2 + 1, (28 - 2)/2 + 1, 20)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # define the second convolutional layer\n",
        "        # the layer accepts input with 20 channels, generate output with 30 channels\n",
        "        # filter dimension: 5, 5, 1\n",
        "        self.conv2 = nn.Conv2d(20, 30, 5)\n",
        "\n",
        "\n",
        "        # fully associate layer 1\n",
        "        # input size: 30 channels * 5 width * 5 height\n",
        "        self.fc1 = nn.Linear(30 * 5 * 5, 120)\n",
        "\n",
        "        # fully associative layer 2\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "\n",
        "        # fully associative layer 3\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # ---- conv1 result ----\n",
        "        # input dimension: (32, 32, 3)\n",
        "        # output dimension: (32 - 5 + 1, 32 -5 + 1, 6) meaning 6 filters are stack together\n",
        "        # ---- pooling result ----\n",
        "        # input dimension: (14, 14, 20) same as the output from conv1\n",
        "        # output dimension: (14 - 5 + 1, 14 - 5 + 1, 20), meaning that 16 filters stack together\n",
        "\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # ---- conv1 result ----\n",
        "        # input dimension: (32, 32, 3)\n",
        "        # output dimension: (32 - 5 + 1, 32 -5 + 1, 6) meaning 6 filters are stack together\n",
        "        # ---- pooling result ----\n",
        "        # input dimension: (14, 14, 6) same as the output from pooling\n",
        "        # output dimension: (14 - 5 + 1, 14 - 5 + 1, 30), meaning that 16 filters stack together\n",
        "\n",
        "        x = x.view(-1, 30 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rFSvWdC6Lj0",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss function and SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1apM_H3B6Q3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# define the loss function as CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# parameters() of a model is the parameters defined in the __init__()\n",
        "# learning rate is 0.001 and momentum 0.9\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# tuning\n",
        "# relu_running_losses = np.zeros(12)\n",
        "# lr0005relu_running_losses\n",
        "# lr00005relu_running_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykdMAUm26yKC",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj440gNY60jx",
        "colab_type": "code",
        "outputId": "76ab49b4-d4d4-4f8d-b56e-688cce96c771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "#train the model twice\n",
        "for epoch in range(3):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    # input the batches one by one into the model\n",
        "    # enumerate() provides a counter (i) to the current iteration, so the program can know the current index\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # feed forward to calculate the output of the current instance\n",
        "        outputs = net(inputs)\n",
        "        # calculate the cross entropy loss \n",
        "        # return a tensor\n",
        "        loss = criterion(outputs, labels)\n",
        "        # calculate the gradient of the weights in the tensor\n",
        "        # loss.grad is updated in this step\n",
        "        loss.backward()\n",
        "        # optimize the weight with the gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # print status\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            # relu_running_losses[epoch * 6 + int((i + 1)/2000 - 1)] = running_loss / 2000\n",
        "            running_loss = 0.0\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.146\n",
            "[1,  4000] loss: 1.758\n",
            "[1,  6000] loss: 1.588\n",
            "[1,  8000] loss: 1.487\n",
            "[1, 10000] loss: 1.402\n",
            "[1, 12000] loss: 1.368\n",
            "[2,  2000] loss: 1.257\n",
            "[2,  4000] loss: 1.217\n",
            "[2,  6000] loss: 1.171\n",
            "[2,  8000] loss: 1.146\n",
            "[2, 10000] loss: 1.124\n",
            "[2, 12000] loss: 1.114\n",
            "[3,  2000] loss: 1.019\n",
            "[3,  4000] loss: 1.014\n",
            "[3,  6000] loss: 0.990\n",
            "[3,  8000] loss: 0.982\n",
            "[3, 10000] loss: 0.985\n",
            "[3, 12000] loss: 0.956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X80UCJIN-NTu",
        "colab_type": "text"
      },
      "source": [
        "plot training result to tune the hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIsP3fg7xJZw",
        "colab_type": "code",
        "outputId": "c0706cef-3d54-4e7b-f893-896b20a878a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot graph\n",
        "print('Finished Training')\n",
        "plot_index = range(2000, 25000, 2000)\n",
        "\n",
        "plt.plot(plot_index, relu_running_losses, \"r.-\", label=\"lr = 0.001\")\n",
        "plt.plot(plot_index, lr0005relu_running_losses, \"b.-\", label=\"lr = 0.005\")\n",
        "plt.plot(plot_index, lr00005relu_running_losses, \"g.-\", label=\"lr = 0.0005\")\n",
        "plt.xlabel(\"number of instances\")\n",
        "plt.ylabel(\"average of cross entropy error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hU1dbA4d9OIyF0pPciSEd6EDAUBWnSpFjAigpXREGvvSt+inr1WhGRchERCAiCoiJNCV06KChdWlA6IZBZ3x97QkJImYSZOZNkvT7nmcmZM3PWjGFW9tl7r21EBKWUUiqrgpwOQCmlVM6kCUQppVS2aAJRSimVLZpAlFJKZYsmEKWUUtkS4nQAWXXVVVdJ5cqVnQ5DKaVylDVr1sSJSAlvvmaOSyCVK1dm9erVToehlFI5ijFmt7dfUy9hKaWUyhZNIEoppbJFE4hSSqlsyXF9IEqpnOf8+fPs27eP+Ph4p0PJ9cLDwylfvjyhoaE+P5cmEKWUz+3bt4+CBQtSuXJljDFOh5NriQhHjx5l3759VKlSxefn00tYSimfi4+Pp3jx4po8fMwYQ/Hixf3W0sszCSR2byyjlo4idm+s06EolSdp8vAPf37OeeISVuzeWNpNbMe5C+cIDwlnwcAFRFWIcjospZTK0fJEC2TRrkUkXEhAEOIvxLNo1yKnQ1JK+VmBAgW8/poiwrBhw6hevTr169dn7dq1aR63Zs0a6tWrR/Xq1Rk2bBhJ6zD9/fff3HDDDVx99dXccMMN/PPPPwBs27aNqKgo8uXLx+jRo70et7fkiQQSXTmafCH5MBgE4fT5006HpJQKABcuXLii53/77bds376d7du3M2bMGB588ME0j3vwwQf59NNPLx773XffAfD666/Tvn17tm/fTvv27Xn99dcBKFasGO+99x4jR468ovh8LU8kkKgKUSwYuICX275M4zKNGb1sNKv/0nIoSgW02FgYNcreetGiRYto3bo13bt3p3bt2lf0Wl9//TUDBw7EGEOLFi04duwYBw4cuOSYAwcOcOLECVq0aIExhoEDBzJr1qyLzx80aBAAgwYNuri/ZMmSNG3a1C9Dca9EnugDAZtEoipEcX+T+2k8pjG9pvZizeA1lIj0am0xpVRmhg+HdesyPub4cdiwAVwuCAqC+vWhcOH0j2/YEP7zH49DWLt2LZs2bUpzqGu/fv347bffLtv/6KOPMnDgwEv27d+/nwoVKlz8uXz58uzfv58yZcpcckz58uUvOwbg0KFDF48tXbo0hw4d8vg9BII8k0CSXJX/KmL6xnDduOvoO70vP9zxAyFBee5jUCqwHT9ukwfY2+PHM04gWdSsWbN050lMnTrVa+fJCmNMjhuplie/ORuXbcyYbmMYNGsQ//7h37zV8S2nQ1Iq7/CkpRAbC+3bQ0IChIXB5MkQ5b2Rk5GRkek+lpUWSLly5di7d+/Fn/ft20e5cuUuO2bfvn1pHlOqVCkOHDhAmTJlOHDgACVLlszW+3FKnkwgAAMbDGTV/lW8vfxtGpdtzK31bnU6JKVUkqgoWLAAFi2C6GivJo/MZKUF0r17d95//3369+/PihUrKFy48CWXrwDKlClDoUKFWL58Oc2bN2fixIk89NBDF58/YcIEnnjiCSZMmMDNN9/s1fficyKSo7bGjRuLtyRcSJDW41pLxCsRsu7AOq+9rlLqUlu2bHE6BImMjBQRkYULF0qXLl288poul0uGDBkiVatWlbp168qqVasuPtagQYOL91etWiV16tSRqlWrytChQ8XlcomISFxcnLRr106qV68u7du3l6NHj4qIyIEDB6RcuXJSsGBBKVy4sJQrV06OHz/ucVxpfd7AavHy97ER93jknKJJkybizQWlDp46SOMxjckXnI/Vg1dTLKKY115bKWVt3bqVWrVqOR1GnpHW522MWSMiTbx5njwxjDcjpQuUZkbfGew/uZ8BMwaQ6Ep0OiSllMoR8nwCAWhRvgXv3/Q+3//xPc/89IzT4SilVI6gCcTtvsb3MbjRYF7/5XWmb5nudDhKKRXwNIGk8N5N79GifAvunHUnmw9vdjocpZQKaD5LIMaYCsaYhcaYLcaYzcaYh9M45jZjzAZjzEZjzDJjTANfxeOJfCH5mH7LdAqEFaDn1J4ciz/mZDhKKRXQfNkCuQCMEJHaQAtgqDEmdeGZncD1IlIPeBkY48N4PFKuUDmm953OzmM7uWPmHbjE5XRISikVkHyWQETkgIisdd8/CWwFyqU6ZpmI/OP+cTlQngDQqmIr/tPxP3zz+ze8tPglp8NRSnlBTirnvmjRIgoXLkzDhg1p2LAhL70UmN9DfukDMcZUBq4FVmRw2D3At+k8f7AxZrUxZvWRI0e8H2AahjQdwqAGg3hx8YvM/m22X86plPKvQC3nDtC6dWvWrVvHunXreO65564oTl/xeQIxxhQAZgDDReREOse0xSaQf6f1uIiMEZEmItKkRAn/VM81xvBRl49oXKYxd8y8g9/iLq+No5TyHR9Vc88R5dxzCp/WwjLGhGKTx2QRiUnnmPrAWOAmETnqy3iyKiI0gph+MTQe05ieU3uy4t4VFMxX0OmwlMrRAqCae44o5x4bG0uDBg0oW7Yso0ePpk6dOp6/QT/xWQIxti7xZ8BWEXk7nWMqAjHAHSLyu69iAeyfMdkozFaxcEW+6vMVN0y6gUGzBjG973SCjI5+VsqXfFzNPeDLuTdq1Ijdu3dToEAB5s2bR48ePdi+fbsjcWXEly2Q64A7gI3GmKS/N54CKgKIyMfAc0Bx4EP3B3fB27VagOTS0PHxEB5uq3xmIYm0rdKWN254gxHfj+D1n1/nqdZPeT1EpfKKAKjmHvDl3AsVKnTx+M6dOzNkyBDi4uK46qqrsvAufc9nCUREfgYyXB1FRO4F7vVVDBctWgTnzoGIvV20KMu/jY+0eITVf63mmZ+eoVGZRnSq3sknoSqlHK3mHhDl3A8ePEipUqUwxrBy5UpcLhfFixf33pv0kryxHkh0NOTLB2fPJv+cRcYYxnYfy+YjmxkwYwCr71tNtWLVvBqmUipZVJR/E0d2dO7cmXnz5lG9enXy58/P559/fvGxhg0bss7d2fPhhx9y5513cvbsWW666SZuuukmAJ544gn69u3LZ599RqVKlfjqq68AmD59Oh999BEhISFERETw5ZdfBuRqhXmnnHtsLLz4IsyfD7/+anvdsuHPf/6kyZgmlC9Unth7YokMS78prJSytJy7f2k5d2+LioIpUyAyEt5Os0/fI1WLVmVK7ylsOryJe+fcS05LwEop5S0ZJhBjTJAxpq+/gvG5okXhnntsIknRqZVVHat35LX2r/Hlpi95Ozb7yUgppXKyDBOIiLiAx/0Ui38MH27HBf73v1f0Mv++7t/0rtWbx398nJ92/uSl4JRSKufw5BLWj8aYke7qusWSNp9H5itVqkDv3vDJJ3DyZLZfxhjD5zd/zjVXXUPfaX3ZfWy3F4NUSqnA50kC6QcMBZYAa9yb9xYld8KIEXZm0rhxV/QyBfMVZGa/mZx3nafXV704e/6slwJUSqnAl2kCEZEqaWxV/RGczzRvDq1a2RlNV1hMrUbxGkzuNZm1B9bywNwHtFNdKZVnZJpAjDGhxphhxpjp7u1f7hpXOduIEbBrF8SkWaIrS7rW6MoL17/AxPUT+WDVB1cem1LK63JSOfeMXjc4OPhimffu3bt7/T1lhSeXsD4CGgMfurfG7n05W7duUL06vPWWnaF+hZ69/lm61ejGI/MfYenupV4IUCnla4Fazj2j142IiLhY5n32bGeXmvAkgTQVkUEi8pN7uwto6uvAfC44GB55BFauhF9+ueKXCzJBTOo5iapFq9JnWh/2ncj+MGGlFMTujWXU0lHE7vVuPfecUM7dk9cNBJ6UMkk0xlQTkT8AjDFVgUTfhuUnd94Jzz0Ho0fbPpErVDi8MDP7zaT52OZ0nNSR/nX706FqB6IqBHg9BqX8aPh3w1l3MON67sfPHWfDoQ24xEWQCaJ+qfoUzpd+Od6GpRvyn06e13MP9HLuGb1ufHw8TZo0ISQkhCeeeIIePXp4/L69zZMEMhJYaIz5E1scsRJwl0+j8pf8+eHBB+HVV2H7drj66it+ydolavNUq6d46qeneH7R84z6eRQLBi7QJKJUFhyPP45LbD13l7g4Hn88wwSSVYFezj0ju3fvply5cvz555+0a9eOevXqUa2aM3X5MkwgxphgoAFwNVDTvfs3ETnn68D8ZuhQeOMNeOcd+PBDr72swSAI5y6cY9GuRZpAlHLzpKUQuzeW9hPbk5CYQFhwGJN7Tfbqv6FAL+ee0esm3VatWpXo6Gh+/fVXxxJIZjPRE4EBInJORDa4t9yTPABKl4Y77oDx4yEuzisvGV05mvCQcABcuCgaUdQrr6tUXhFVIYoFAxfwctuX/d6Cnzp16sVO6pRb6uQBthz7xIkTERGWL1+eaTl3EWHixIkXy7YnlXMHLinnnt7r/vPPP5w7Z7+C4+Li+OWXX664H+eKiEiGG/AO8D7QGmiUtGX2PF9tjRs3Fq/bvFkERF56yWsvuWzPMnn2p2el/FvlpdSbpWTv8b1ee22lcpotW7Y4HYJERkaKiMjChQulS5cuXnlNl8slQ4YMkapVq0rdunVl1apVFx9r0KDBxfurVq2SOnXqSNWqVWXo0KHicrlERCQuLk7atWsn1atXl/bt28vRo0czfN1ffvlF6tatK/Xr15e6devK2LFj04wrrc8bWC1e/j7OtJy7MWZh2nlH2nk3lXkm2+XcM9O5M6xZA7t321ULvWTLkS00H9uc2iVqs/jOxRdbJkrlJVrO3b8Copy7uw9ktoi0TbU5kjx8auRIOHzYrp3pRbVL1GZij4ms3L+SIXOH6Ex1pVSu4VEfiJ9icVbbtnaRqbfestV6vahnrZ482+ZZPl/3OR+u8l5HvVJKOcmTiYS/GGPeN8a0NsY0Stp8Hpm/GWPLm2zdCu5Zot70QvQLdK3RleHzh7Nk9xKvv75SgU5b3/7hz89Z+0BSOn/elnuvWRMWLPD6yx+PP07zsc35++zfrBm8hgqFK2T+JKVygZ07d1KwYEGKFy8ekGt75xYiwtGjRzl58uRl81x80QeSd9ZE99Sbb8Ljj8PatXDttV5/+W1x22j2aTNqFK/B0ruWEhEa4fVzKBVozp8/z759+4iPj3c6lFwvPDyc8uXLExp6ac1bRxKIMaYU8BpQVkRuMsbUBqJE5DNvBuIpnyeQY8egQgW4+Wb43/98coo5v82h+5fdGdhgIONvHq9/kSmlfM7vo7DcxgPzgbLun38HhnszCH+IjYVRo+xthooUgXvvhalTr2jd9Ix0q9mNF6NfZOL6iby34j2fnEMppXzNkwRylYh8BbgAROQCOayYYmwstG8PzzxjbzNNIg8/bEu8v+e7L/dn2jxDj2t6MOL7ESzcmVY3k1JKBTZPEshpY0xxQACMMS2A4z6NyssWLYL4eDs699w5+3OGKleGPn3suuknTvgkpiATxMQeE6lRvAa3TLuFXcd2+eQ8SinlK54kkEeB2UA1Y8wvwETgIZ9G5WXR0cmTy0WgZUsPnjRihE0en/muq6dgvoLM6j+LC64L9JzakzPnz/jsXEop5W2erIm+FrgeaAncD9QRkQ2+DsyboqLsqNw777QJZNUqD57UtCm0aeOVddMzUqN4Db7o/QXrD67nvjn36Vh5pVSO4UkLBBG5ICKbRWSTiJz3dVC+EBUFn39uS169/LKtWpKpESNgzx6YPt2nsXW+ujOvtHuFLzZ+wduxb/v0XEop5S0eJZDc5O234cwZePZZDw7u2hVq1PDauukZebLVk/Sp3YfHf3ycH//80afnUkopb8hzCaRmTfjXv2DsWFi/PpODg4LsuumrV8PSpT6NyxjD5zd/Tu0Stek3vR87/9np0/MppdSVyjSBGGNijDFdjDFZSjbGmArGmIXGmC3GmM3GmIfTOMYYY94zxuwwxmzwV42t556DokVh+HAPGhYDB8JVV9l1032sQFgBZvWbhUtc9Jjag9MJp31+TqWUyi5PksKHwK3AdmPM68aYmpk9we0CMEJEagMtgKHuWewp3YRdLvdqYDDwkYevfUWKFoWXXrLDeWfOzOTg/PlhyBCYMwfSWObS26oVq8aXvb9k0+FN3D37bu1UV0oFLE9GYf0oIrdhVyLcBfxojFlmjLnLGBOawfMOuEdwISInga1AuVSH3QxMdC+YtRwoYowpgx8MHgx169plQDItzzN0KOTLZ9dN94OO1Tsyqv0ovtr8FW8ue9Mv51RKqazy6LKUeyLhncC9wK/Au9iE8oOHz68MXAusSPVQOWBvip/3cXmSwRgz2Biz2hiz+siRI56cMlMhITYf7NxpR+pmqGRJeylrwgTw0vkz81jLx+hXpx9P/PgE3+3wfnl5pZS6Up70gcwElgL5gW4i0l1EporIQ0ABD55fAJgBDBeRbE3rFpExItJERJqUKFEiOy+Rpg4doHt3ePVVOHgwk4MffdQ2VT70z4JQxhg+6/4Z9UrVY8CMAez4e4dfzquUUp7ypAXynojUFpFRInIg5QOZVXZ0X+KaAUwWkZg0DtkPpFwUo7x7n9+MHm3Lmzz9dCYHXnMNdOkCH3wAZ8/6JbbIsEhm9ZtFkAmix5c9OJVwyi/nVUopT3iSQGKNMY+6R2PNMMY8YowJz+xJxtYo/wzYKiLpzY6bDQx0j8ZqARxPnaR87eqrbe3Ezz+3S4BkaORIewnLR2Xe01KlaBWm9pnK1rit3DnrTu1UV0oFDE/WA/kKOAkkfWveChQRkVsyeV4r7KWvjbgr+QJPARUBRORjd5J5H+gEnAHuEpEMF/vwxXogx4/bRFKzJixZYle3TZMINGkCp0/Dli12noifvB37NiO+H8Gr7V7lqdZP+e28SqncwRfrgYR4cExd91DcJAuNMVsye5KI/AxkuFKS2Ow11IMYfKpwYXjlFbj/fpg2Dfr2TefApHXTb7sN5s2zM9X95JEWj7D2wFqe+ekZGpRqQJcaXfx2bqWUSosnf0KvdV9eAsAY0xzw4ZKAzrjnHmjQAB57LJMujltugfLlbXkTPzLGMKbbGBqWbshtMbfx+9Hf/Xp+pZRKzZME0hhYZozZZYzZBcQCTY0xG40xOaoqb0aCg+1w3j17bL2sdIWG2insixbBmjX+Cg+A/KH5mdlvJqHBofT4sgcnzvlmrRKllPKEJ30glTJ6XER2ezWiTPh6TfTevWH+fPj9dyhbNp2Djh+366Z37QpffOGzWNKzcOdCbph0A91qdmNG3xkEZa3KjFIqD3JkTXR3gigCdHNvRURkd9LmzWACwZtvwvnz8OSTGRxUuDDcdx989ZVtsvhZ2ypteevGt5i1bRavLHnF7+dXSinwbCLhw8BkoKR7+58xJketSJgVVavaOYMTJ8LKlRkc+LC7NqQP103PyLDmwxjYYCDPL3qe2b/NdiQGpVTe5sklrA1AlIicdv8cCcSKSH0/xHcZX1/CAjh50g7rrVoVfvklg2G9t94K33wDe/faVomfnT1/ljbj2/Bb3G+svG8l11x1jd9jUErlDI5cwsIOxU1M8XMimQzPzekKFoTXXoPYWJgyJYMDR4yw2WbsWL/FllJEaAQxfWOICI3gxkk38vzC54ndG+tILEqpvMeTFsijwCAgqfB5D2C8iGRWgtAn/NECAXC57LLohw/bKu7586dzYNu28McfdgtNtzixT3246kOGzrPTaSJCIlgwcAFRFaIciUUpFZj83gJxLyK1HLgL+Nu93eVU8vCnoCA7rHffPtuxnq4RI+wlrGnT/BZbasfjj2PcjcL4C/Es3LXQsViUUnlHhglERFzAByKyVkTec2+/+ik2x7VubWel/9//2RyRps6dbQ0UP6ybnp7oytGEh4RjMAjC+oPrtWaWUsrnPOkDWWCM6e2uW5XnvPGGzQtPPJHOAUFBdtjW2rWweLFfY0sSVSGKBQMX8Eq7V+hbuy9fbdGFqJRSvudJH8hJIBK7RG08tgNdRKSQ78O7nL/6QFJ69llbK2vZMohKq2vh7FmoVAmaN7dL3zrIJS5uj7mdKZumMP7m8QxqOMjReJRSgcGpiYQFRSRIRMJEpJD7Z0eSh1P+/W8oU8ZO/XC50jggIsIue/vNN7B1q9/jSynIBDG+x3g6VO3APbPvYd72eY7Go5TKvTyZSLjAk325WYEC8PrrsGpVBkuBDBkC4eF+Wzc9I2HBYcT0jaFh6YbcMu0Wlu9b7nRISqlcKN0EYowJN8YUA64yxhQ1xhRzb5VJY93y3O7226FZM1vi5FRaCwOWKAGDBtkp7IcP+z2+1ArmK8i82+ZRpkAZunzRhW1x25wOSSmVy2TUArkfWANc475N2r7GLgKVpyQN6/3rLzsqK02PPGLXx/3gA7/Glp6SkSWZf/t8QoJC6Pi/juw/4dfVgpVSuZwnnegPich//RRPppzoRE/pttsgJga2bbP95pfp3t1OYd+zx/aNBIBfD/zK9eOvp1KRSiy9aylFwos4HZJSys+c6kT/rzGmpTHmVmPMwKTNm0HkJK+/bmtjPf54OgeMGAFxcfZSVoC4tsy1zOo/i9/ifqP7lO6cPZ/RillKKeUZTzrRJwGjgVZAU/fm1SyWk1SoYEdlffUVLF2axgFt2th1099+O50hW85oV6Udk3pO4uc9P3NrzK0kuhIzf5JSSmXAk4mETYDrRGSIiDzk3ob5OrBA9thjdlXb4cPTyBFJ66b//jvceae9nBUg+tXtx7ud3mXWtlkMmTtEZ6srpa6IJwlkE1Da14HkJPnz2470tWthwoQ0DihXziaSSZOgffuASiIPNX+IJ1s9yZi1Y3hx8YtOh6OUysE8SSBXAVuMMfONMbOTNl8HFugGDLCz0p96ylZ0v8TPPyffP3fOrp8eQF5t9yp3N7ybFxe/yMerP3Y6HKVUDhXiwTEv+DqInMgYePddOzfktddg1KgUD0ZH20mFZ8/aa1zXBNZCT8YYPun2CYfPHGbI3CGUjCxJr1q9nA5LKZXDeDIKazGwCwh1318FrPVxXDlC06YwcKDtL//zzxQPREXBggW2syQ8HMaMcaxSb3pCgkKY2mcqLcq34NYZt7J4lzOFIJVSOZcno7DuA6YDn7h3lQNm+TKonGTUKLuO1GOPpXogKsqW8n3zTfjuO9sfEmDyh+ZnzoA5VC1alZu/vJkNhzY4HZJSKgfxpA9kKHAdcAJARLYDJX0ZVE5StqwtbxITk05Xx5Ah0KqVHbJ18KC/w8tU8fzFmX/7fAqEFaDT/zqx69gup0NSSuUQniSQcyKSkPSDMSYECKzrMQ579FE7K334cEhMPb0iKMiumX7mDPzrX47El5kKhSsw//b5nL1wlo7/60jcmTinQ1JK5QCeJJDFxpingAhjzA3ANMDZRS8CTESEvVq1fj2MG5fGATVrwosvwowZdgtAdUrWYc6AOew5vocuX3ThdMJpp0NSSgU4T2phBQH3ADdiF5OaD4wVh2ahOV0LKz0icP31tkbW9u1QuHCqAy5cgBYt7CLrW7ZAsWKOxJmZ2b/NpufUnnSs1pGv+39NaHCo0yEppbzAqVpYLhH5VERuEZE+7vt6CSsVY2y13rg4u3rhZUJC4LPP4OhRW7U3QHWv2Z1Pun7Ctzu+5Z7Z9+CSwCnHopQKLJ5cwlIeatQI7rrLzg/Zvj2NAxo0sD3uEyfCt9/6PT5P3dvoXl5u+zKTNkziiR/TWwxeKZXX+SyBGGPGGWMOG2M2pfN4YWPMHGPMemPMZmPMXb6KxZ9efRXy5YORI9M54OmnoXZtuP9+OHHCr7FlxdOtn2Zo06G8uexN3ol1fpVFpVTgyVICMcYEGWM8XQ99PNApg8eHAltEpAEQDbxljAnLSjyBqHRpmyNmz4Z77kmjDFa+fLanff9+eCJw/7o3xvBup3fpU7sPj37/KJM3THY6JKVUgPFkIuEXxphCxphIbGHFLcaY1NPmLiMiS4C/MzoEKGiMMUAB97EXPAs7sLVoYftExo2zVU2WLUt1QPPmdszvRx/B4sCdAR4cFMyknpOIrhzNnV/fyfd/fO90SEqpAOJJC6S2iJwAegDfAlWAO7xw7veBWsBfwEbgYZG0e2yNMYONMauNMauPHDnihVP7VmysTSAACQl2qfTff0910MsvQ9WqcO+9do5IgAoPCWdWv1nUKVGHXlN7sfqvwBsBp5RyhicJJNQYE4pNILNF5DzemUjYEVgHlAUaAu+nd3lMRMaISBMRaVKiRAkvnNq3oqPtlargYFvm5K+/oF49eOaZFLkif347wXDHDnj+eSfDzVTh8MJ8e9u3lIgsQefJndl+NK0RAkqpvMaTBPIJtphiJLDEGFMJd1mTK3QXECPWDmAnEFhla7MpqZbiyy/bK1R//AH9+tkO9tq14euv3bUV27aFwYNtNcZVq5wOO0NlCpZh/u3zEYTrx1/PUwueInZv4KxzopTyv0wnEqb5JGNCRCTT/gpjTGXgGxGpm8ZjHwGHROQFY0wpbIXfBiKSYR2NQJ1I6IklS2DoUNi0CTp3hvfeg2pXHYc6daBoUVizBsICexzBZ2s/49459wL28tZPA38iqkKUw1EppTLjyERCY8zD7k50Y4z5zBizFmjnwfOmALFATWPMPmPMPcaYB4wxD7gPeRloaYzZCCwA/p1Z8sjp2rSxqxi+/bZNJnXqwAvvFObse5/arPLaa06HmKnDpw8T5P61ib8Qzxcbv3A4IqWUUzwpZbJeRBoYYzoC9wPPApNEpJE/AkwtJ7dAUvrrLztXZMoU25f+XsXRdPn5SZth6tVzOrx0xe6Npf3E9iQkJuASF6HBoUzoMYH+dfs7HZpSKgOOtECw9a8AOmMTx+YU+1Q2lS0LX3xh+0rCwqDropH0CJrNrtuetnWzAlRUhSgWDFzAy21fZs6AOTQt25QBMwbw5I9PkuhKXYpYKZWbedIC+Ry7iFQVoAEQDCwSkca+D+9yuaUFklJCgq2j9dJz50k8d4Gnb1zNY7Nbky+f05FlLiExgWHfDuOTNZ9wU/Wb+KL3FxQJL0AhPJIAACAASURBVOJ0WEqpVJxqgdwDPAE0FZEzQBh2BJXykrAwePxx2Pp7CF3L/sqz37embs0E5s93OrLMhQWH8XHXj/moy0f88OcPNB/bnG1x25wOSynlBx5V4wXKA88YY0YDLUVE1z71gQoVDdNWV2F+ZC/MoUN06gR9+sCePU5HlrkHmjzATwN/4p+z/9B8bHO++f0bp0NSSvmYJ6OwXgceBra4t2HGmMAfLpRTlSnDjf/txsb46rzabTnz5kGtWvD66/ZSVyBrXak1qwevpnqx6nSf0p3Xlr6GVv5XKvfypA9kA9AwqcyIMSYY+FVE6vshvsvkxj6Qy4hAp06wbBm7v9vK8NHlmTXLLmz4wQfQvr3TAWbszPkz3Dv7XqZsmkLfOn0Z130ckWGRToelVJ7mVB8IQMpe0dRr7SlvMwY++QREqPTSPcyMEebOtYOzOnSA/v1tMd9AlT80P5N7TeaNDm8wbfM0rht3HbuO7XI6LKWUl3mSQF4DfjXGjDfGTADWAK/6NixF5cr2utX338OECXTubOcavviiLYVyzTXw1ltw/rzTgabNGMNj1z3GvNvmsevYLpqMacKiXYucDksp5UUZXsJyr4feB1gKNHXvXikiB/0QW5ryxCWsJC6XXWh90ya7jnqZMgD8+ScMGwZz59rZ7B98YEdyLVpkCzlGBVhlke1Ht3Pzlzfz+9HfeafjO/yr2b8wRqcSKeVPvriE5UkfyGpvn/RK5KkEAvDbb3Yp3M6dYcaM5Drx2EWrhg2D3btt5V8RWwV4wYLASyInzp3g9pjbmfP7HO5ueDcfdvmQfCE5YKKLUrmEU30gPxpjRhpjKhhjiiVt3gxCZaBmTXvdauZMmD79koe6d7cNk7ZtITHRNljOnoWbboKuXe3y61OmwObNzl/qKpSvELP6z+KZ1s8wbt042k5oy4GTB5wNSil1RTxpgexMY7eISFXfhJSxPNcCAdt73qIF7N1rM0bx4pc8HBsL7drZYb7BwfYy1sGDsHVrclWUsDA7HLh+fVtqK+m2TJlLGjV+MX3LdAbNGkSR8CLM7DeTZuWa+TcApfIgRy5hBZo8mUAA1q+HJk3sEKxJky57ODb28j6QhATYtg02boQNG5JvU47gKl780qRSv77tV8mf37dvZ8OhDdz85c0cOHmAT7p+wqCGg3x7QqXyOKf6QIYCk0XkmPvnosAAEfnQm4F4Ks8mEIDnnrOrVM2da/tEsunvv5OTSVJi2bgxebVEY6B69UuTSr16tmpwUFDaySo74s7E0W96P37a+RPDmw/nzRvfJCQoJPsvqJRKl1MJZJ2INEy171cRudabgXgqTyeQc+egUSM4ccJ2bBRKcwXgbHG5YOfOS5PKhg12xd2kX5HISKhY0a7v7nIld9i3bJn9815wXWDk9yN5d8W7tK/Snql9plI8f/HMn6iUyhKnEshGoL64D3TPRN8gInW8GYin8nQCAVixwn5j33cffPyxz093+rTtdklKKnPm2GHESYoVg9tusw2i66+HiIjsnWf8uvHc/839lCtYjq/7f029UoG7JopSOZFTCeRNoBJ2bXSwi0rtFZER3gzEU3k+gQCMGGGXNVy40F5H8qPYWFtKJSHBXs5q2hR+/dWO/oqIsI917my3SpWy9trL9y2n19RenDh3gok9J9KrVi/fvAml8iCnEkgQMBjo4N71AzBWRBxZPUgTCLazor67FNmGDb7v8U4ldR/I2bP253nzbPfMTve4vdq1k5NJq1YQGpr5a/918i96Te3Fiv0reLbNs7wQ/QJBxtOKO0qp9OgoLDSBXLRokZ0A8uijtqZJgBCxfSRz59qEsmSJnYNSsCDceKNNJjfddHFSfZriL8QzZO4QPl/3Od1rdmdSz0kUyue9/h6l8iJNIGgCucQDD8Cnn8KyZdC8udPRpOnkSdvRPm+e3ZKGEF97LXTpYhNKs2Z2/kpKIsL7K9/nkfmPUKFwBXpd04s+tfsQVSHAptjnMN4aQadyHk0gaAK5xIkTdtJGoUKwdi2BvgauiL3ilpRMli2zo7mKFbPV6zt3trcp50n+d+V/GfbtMACCTTDje4zn9vq3O/QOcrY5c6B3bzu5NDQU3n0XevSAUqX8P5lUZd2VJn+/JhBjzCQRucMY87CIvOvNk14JTSCpzJtn/5S/6y64+uoc9afl33/DDz/Yt/Dtt3DkiP0ia9Eiue/ku1OjeHbhs7hI7nLrVL0TI6NG0q5KOy3KmIk//4SYGFsJZ9mytI+JjLTzftLaypa1gyWUs374wZYnunAh+/Xu/J1AtmA7zr8FooFL/qWKyN/eDMRTmkDS0KkTzJ9v/6UHajXFTLhcsHp1cutk1Sq7v2DtWE72bA9BCeAKo0nYQHYEz+LYhUPUKHgtg64eSbdqt1AoMpSICAgPt6PBPOmwT09OvswjYqcIxcTYbf16u79hQ1vI4H//s31SoaHw6qv2dseO5G3nzkvrpkVEQLVqaSeX8uUvv/SovOPoUVi6FBYvttu6dcnzsYKD7XziJ5/M2mv6O4EMAx4EqgL7uTSBaC2sQPLss/DKK/a+MfDCC3bWeg526BB8950dH7Dxn1iovAh2RcO+KAiJh3qToeVoKLENjleA5cNh7b1wzna2BwfbL7+0tqQkk9YWFwcTJ9rilGFhVz5R0h9cLptwZ860SWP7dvtr0LIl9OoFPXtClSr22MyS44ULtuRayqTyxx/Jt/HxyceGhdnqBGkll0qVICQkZydjfzp40A44WbLEJoxNm+z+8HD7uVWpApMn2/8/Sb+XAd0CSXHSj0TkQW+e9EpoAklD0uSM+Hj7Z0q5cjB+vF2+MIdLOe8kNNSOGahZ0w4dPn3GxS+HvyXm4JtsPbuYcFOI5iH30yzxYULjy3H2LGlu8fFp7z979vJ15wsUsIPdmjZN3ooHwET5CxfsX6hJl6f277df2G3b2qRx880Zj3TLDpcL/vorObFs335pokkqhQM2llKl4MAB+7zgYOjTx15ljYy8fCtQIO394eGe98/kpGS1d69NFEkJ4/ff7f7ISLjuOjsp9/rrbasxqWszR/WBpDpxA6C1+8clIrLBm0FkhSaQdCT9dhUoAO+9Z/9FDxpk/4QPhG+8K+DJP5xV+1fxVuxbTNsyjSATxK31bmVE1Ajql6qfpXP9/LMdbnzunP3Sa98edu2yy7Ik/VOpUuXShNK4sf3YfS0+Hn780SaN2bPtZY7wcHsFs1cve428aFHfx5EWEftXdMpWy+zZtnpBkrAwe3ksK+N2jEk7saTeTpywn0tiov1D48034YYb7N9SXqz4ky0iti8qKVksWZI8V6pwYWjd2iaLNm1spaIQH5WDc6oFMgw7kTDGvasnMEZE/uvNQDylCcQDZ8/aS1pvvAFFisB//gO33ponhtrs/Gcn7654l7Frx3L6/GlurHYjI6NG0qFqB4873NNKWCdOwJo19lJR0rZ7t33MGFsqP2VSadDAO4PiTp60AwxiYuzcmlOn7Bdi1642aXTqZL9AA1HK1mPSZZcWLdytx9Pe3f7+2yb9tBQoYAcDlCuX/la6tPe+uEXsHxwpWxhJw9eLF7eJIqmFUa+e//qRnEogG4AoETnt/jkSiBWRrP1p5yWaQLJg40ZbM2vFCujYET76KPlieC7399m/+WT1J7y38j0OnjpIg1INGNlyJP3q9CM0+Ap62FM4fNh2/KdMKocP28dCQ22xgKSE0qyZTTKefFkcPWqH3MbEwPff2y/GEiXskNtevezaL2FhXnkLPuevy0qpL3W+9Zb922n/fnvZbf/+5O2vvy5fYM0Ye8ktoyRTtqxtMST9HZL03tq0sRNlU7Ywkn4PSpdOThZt2tjfAadGtTlZTLGpiMS7fw4HVomII9XuNIFkUWKiTRxPPmnvv/QSDB/uu3ZygDl34RxfbPyC0bGj2XJkC+ULlefh5g9zX6P7KBxe2KvnErHXtlMmlNWrbesFbEuhUaNLWyqHDtkvnTp17HNjYuzPiYm28nGvXnZr2VJHPGXG02TlctnBEikTSsoEk7T9ncY40/z5bTIpUMDOaUpMVdCpYsXkZHH99XZAQaA0/J1KII8Cg4CZ7l09gPEi8h9vBuIpTSDZtHcv/Otf9sL0tdfa3ujGjZ2Oym9c4uK7Hd8xetloFu5aSMGwgtzf+H6GNR9GhcIVfHdel+1sTkooK1faIZkpRzOlVKuWHTXVq5dNNoHy5ZMXnT1rBwGklVxWrLj0Embv3rbfpXJlR0POkC8SCCKS6QY0Aoa5t2s9eY6vtsaNG4vKJpdLZPp0kdKlRYKCRB59VOTUKaej8rvV+1fLgOkDJPjFYAl5KURuj7ldfj3wq9/On5AgsnatSI8eIsaIgL0dPtxvIagrtGyZSESESHCwvV22zOmIMgesFi9/H/uslIkxZhzQFTgsInXTOSYa+A8QCsSJyPWZva62QLzg2DF44gn45BM7YP+jj2yFwzxm97Hd/Gf5f/h07aecPn+aDlU78FjLxygQWoDFuxcTXTnap7W30upkDvThpypZTho2DDmsFpYxpg1wCpiYVgIxxhQBlgGdRGSPMaakiBzO7HU1gXjRzz/bTvZt22DAAHjnHduTmMf8c/YfxqwZw7sr3uXAqQMY93/5QvKxYOACnyeRnPQlpHIuXyQQn40HEJElQEblTm4FYkRkj/v4TJOH8rJWrewF+RdegBkz7AX4zz/P2kD9XKBoRFH+3erf7Bq+iz61+iAILlzEX4hn4a6FPj13VJQd36DJQ+VEHiUQY0wlY0wH9/0IY0xBL5y7BlDUGLPIGLPGGDMwg/MPNsasNsasPnLkiBdOrS7Klw+ef94mkjp14O677XWV7dudjszvwoLDeDTqUSJCIjAYBOH7P77nxLkTToemVEDKNIEYY+4DppO8pG15YJYXzh0CNAa6AB2BZ40xNdI6UETGiEgTEWlSokQJL5xaXaZWLTt+9JNPbGn4evXgtdcur+2Ry0VViGLBwAW80u4V/tX0X/y852eaj23OtrhtToemVMDxpAUyFLgOOAEgItuBkl449z5gvoicFpE4YAnQwAuvq7IrKAgGD4atW6FbN3j6aTvUd/lypyPzq6gKUTzV+in+2/m//HDHDxw9c5SmnzYlZmtM5k9WKg/xJIGcE5GLf4YaY0IAb1wk/xpoZYwJMcbkB5oDW73wuupKlSkD06bB11/bEVstW8JDDyXPiMtD2lZpy5rBa6hdoja9v+rNkz8+SaIrMfMnKpUHeJJAFhtjngIijDE3ANOAOZk9yRgzBYgFahpj9hlj7jHGPGCMeQBARLYC3wEbgJXAWBHZlN03onyge3fYssVOQPzgA6hd2yaVPKZC4QosuXMJgxsN5vVfXqfT5E7EnYlzOiylHOfJTPQg4B7gRuyaIPOxX/aODNXRYbwOWbHCDvnduNGOOW3RwiaYPDZ8aOzasQydN5TSBUoT0zeGxmXzzmx+lbPlqHkgvqIJxEHnz8OwYfDxx/bn0FC7EmLbts7G5Wer9q+i91e9OXz6MB91+Yi7rr3L6ZCUypQj80CMMRuNMRtSbUuNMe8YY3L2QhMqa0JDbbW4pHKi58/blYvGjrUrHOURTcs1Zc3gNVxX8Trunn03D37zIOcupFNLXKlczJM+kG+BucBt7m0OsBo4CIz3WWQqMEVH27kjwcH2tlIle2mrXj2YNSvPTEIsEVmC+bfP57GWj/Hxmo+JnhDN/hP7nQ5LKb/yJIF0EJEnRWSje3sauF5E/g+o7NvwVMCJirJFm15+GRYutDWtZ7oLNffsadfj/PlnZ2P0k5CgEN644Q2+6vMVGw9tpNGYRizetdjpsJTyG08SSLAxplnSD8aYpkDSygR557qFSpay/oYxdqWjjRthzBi7/mvr1raDffNmpyP1i1vq3MLK+1ZSJLwI7Se2553Yd8hpfYtKZYcnCeRe4DNjzE5jzC7gM+A+98qEo3wZnMpBQkLspawdO+wM9sWL7ZJ8d99t1yLJ5WqXqM3Ke1fStUZXHv3+UW6NuZXTCaedDkspn/J4FJYxpjCAiBz3aUSZ0FFYOcTRozaRvP++7XQfNsyWkC9a1OnIfMolLl7/+XWe+ekZ6pSsw8x+M6lerLrTYSnl3DBeY0wXoA4QnrRPRF7yZiCe0gSSw+zeDc89B5Mm2QWln3rKTkyMiHA6Mp+av2M+t8bcSqIrkf/1+h9da3R1OiSVxzk1jPdjoB/wEHYi4S1AJW8GoXKxSpVgwgRb7bdlS3j8cahRw5aNT72gdC7SsXpHVt+3mipFq9BtSjdeWPQCLnE5HZZSXuVJH0hLERkI/CMiLwJR2FLsSnmufn2YO9eO3Cpb1vaNNGgAc+bk2qG/VYpWYdndyxjYYCAvLn6RblO68c/Zf5wOSymv8SSBxLtvzxhjygLngTK+C0nlatHRtrrv9Ol2ImL37tCmDSxb5nRkPhERGsH4m8fzQecP+P6P72nyaRM2HNrgdFhKeYUnCWSOe/nZN4G1wC7gC18GpXI5Y6B3b9i0yZZF2bHDzh/p2dOWks9ljDEMaTqExXcu5uz5s7QY24IvNuo/IZXzZZhA3IUUF4jIMRGZge37uEZEnvNLdCp3Cw2F+++3CeSVV+wExbp17XDg/blvVnfLCi1Ze/9aGpdtzG0xtzH8u+GcTzzvdFhKZVuGCUREXMAHKX4+5/QwXpULRUbaxav++MMO950wAapXt5MVjx1zOjqvKl2gND8N/IlhzYbx7op3afppU55a8BSxe2P9cv7YvbGMWjrKb+dTuZsn5dxHY9f1iHGqhHtKOow3D9i50w79nTwZihSB226DkiWhQ4dcVT7+hYUv8OKSFwEwGKoVrUbBfAUJDgomyAQRZIIINvZ+0r7UP2d6DEEX7x8+fZg5v80hURLJF5KPnwb+RFSF3PN5qow5Mg/EGHMSiAQSgbPYobwiIoW8GYinNIHkIevWwQMP2LVIwF7ymjsXbrjB2bi8ZNTSUTyz8JmLw3trXVWLasWqkehKxCUuXOIiUez9pH2pf87omNT7TiWc4sz5MxfPXyJ/CQY3HkyvWr24tvS1GGOc+iiUH/gigYRkdoCIFPTmCZXyWMOGtlz8qlXgctlRW9262ctcDz8M5co5HeEVia4cTb7gfCQkJhAWHMZn3T/zaYsgdm8s7Se2JyExgSATRMXCFXn959d5demrVCpciV61etGrVi+iykcRHBSc+QuqPM+TFojBlnGvIiIvG2MqAGVEZKU/AkxNWyB5TGwstG8PCQm23larVnYuSXCwvbQ1ciTUqeN0lNkWuzeWRbsWEV052i+Xk1KfL+5MHHN+m0PMthi+/+N7EhITKBVZih7X9KBXrV60rdyW0OBQn8elfM+pS1gfAS6gnYjUMsYUBb4XkabeDMRTmkDyoNhYWLTIziGJirJ9JG+/DZ99BmfPQpcu8Nhjdj6JXobJthPnTvDt9m+ZsXUG87bP4/T50xQJL0K3Gt3oVasXN1a7kfyh+Z0OU2WTUwlkrYg0Msb8KiLXuvetF5EG3gzEU5pA1EVHj8KHH8J770FcHDRrZhNJz562haKy7ez5s/zw5w/EbI1h9m+z+Sf+H/KH5uem6jfRu1ZvutToQqF8jnSDqmxyKoGsAFoCq9yJpAS2BXKtNwPxlCYQdZmzZ+3Q39Gj7VDgatVgxAi4885cX7TRH84nnmfx7sXEbI1h5raZHDx1kLDgMDpU7UCva3rRvWZ3SkSWcDpMlQmnEsht2GKKjYAJQB/gGRGZ5s1APKUJRKUrMdEuq/vGG7ByJZQoYSv/Dh0KxYs7HV2u4BIXy/ctJ2ZrDDO2zmDXsV0EmSDaVGpDr2t60bNWT8oXKu90mCoNTpZzvwZojx3Cu0BEHKs3oQlEZUoEli61iWTuXNsKueceePRRqFLF6ehyDRFh/aH1F5PJliNbAGhWrhm9rrEjuuLOxPl1kIBKn1MtkPeAL0UkIKrdaQJRWbJ5s720NXmybaH06WP7SZp49d+RArbFbWPm1pnEbIth9V/236jBDmoIDQ5ldv/ZdKze0ckQ8zSnEsgg7CWsmsBMbDJx7BtcE4jKlv37bWf7xx/DiRPQtq1dm6RjRx255QN7ju9hyNwhzN0+95L9dUvWpXXF1rSu2Jo2ldpQrlDOnsuTkzh2Cct98mJAb6A/UFFErvZmIJ7SBKKuyPHj8Omn8M478NdfUK+ebZH0729nuiuvSTlxMSQohEENBrH7+G5+2fsLpxJOAVClSBXaVGpzMaFUL1ZdZ8T7iNMJpBm2JXIzsFVEunkzEE9pAlFekZAAU6bAm2/ay1zly8Pw4bYS8ObNl847UdmW1kTJC64LrD+4nqV7lrJk9xKW7llK3Jk4AEpFlqJ1pda0qdiG1pVaU69kPZ0V7yVOXcJ6A+gJ/AFMBWaKiGMlUjWBKK8SgW+/tR3uixfbysDnztn9YWG2xLwmEZ8SEbbFbWPpnqUXk8qe43sAKJyvMNdVvO5iC6VJ2SaEBYc5HHHO5FQCuR+YISJx3jxxdmkCUT6zapVdanfTpuR9AwfCuHE6MdHP9hzfw9LdyS2UrXF24Gd4SDjNyzW/eNkrqkIUBcIKOBxtzuDkMN6iwNVAeNI+EVnizUA8pQlE+VRsLLRrl9wKAahQAe691yaX8jrHwQlHTh/h5z0/X2yh/HrwV1ziItgE06hMI1pXbE3JyJKcSjhF56s765DhNDjVArkXeBgoD6wDWgCxItLOm4F4ShOI8rmk2lutWsHhw/DJJ/DDDxAUBF272lUUO3bUVomDTpw7Qeze2IuXvWL3xnLeZVd3DDJBPN7ycR6/7nGKRhR1ONLA4VQC2Qg0BZaLSEP3pMLXRKRXJs8bB3QFDotI3QyOa4pdsKq/iEzPLGBNIMoRf/5pR2+NG2eTSsWKtlVyzz1QtqzT0eV5Ly9+mRcWv3BxbRWA0KBQOlXvxIC6A+heszuRYZEORug8XySQDJe0dYsXkXh3APlEZBt2TkhmxgOdMjrAGBMM/B/wvQevp5RzqlaFUaNg716YNg1q1LCrJlasCD162I74xESno8yzOlTtQL7gfASbYCJCIhjXfRwPNXuItQfWcmvMrZQcXZIBMwYw+7fZJCQmOB1uruFJC2QmcBcwHGgH/AOEikjnTF/cmMrAN+m1QIwxw4Hz2BbON9oCUTnKH3/YVsnnn9tWSaVKyX0l2irxu7SGDLvExdLdS5myaQrTt0zn6NmjFAkvQu9avRlQdwDRlaPzzDBhR+eBuAO4HigMfCcimabxjBKIMaYc8AXQFhiHJhCVUyUkwNdf276SBQts30i3brav5MYbbd+Jctz5xPP88OcPTNk0hVnbZnEq4RSlC5SmX51+DKg7gGblmuXqSYyOJ5Asv3jGCWQa8JaILDfGjCeDBGKMGQwMBqhYsWLj3bt3+yxmpa7Ijh3JrZIjR6By5eRWSZkyTken3M6cP8Pc3+cyZdMU5m6fS0JiAlWLVqV/nf4MqDeAuiXT7bbNsXJbAtkJJKX7q4AzwGARmZXRa2oLROUI584lt0p++skux9u9OwweDDfcoK2SAHI8/jgzt81kyqYp/Pjnj7jERd2SdRlQdwD96/anatGqTocIwII/F7BkzxI6VeuUrWHKuSqBpDpuPHoJS+VW27cnt0ri4myr5L77bKukdGmno1MpHDp1iGlbpjFl0xSW7bUFyJuXa86AugPoW6cvZQp6txWZ6Erk8OnDHDx1kIOnDnLg1IHL7h84eYD9J/YTnxiPwRAeEs6CgQuynERyVAIxxkwBorGti0PA80AogIh8nOrY8WgCUbnduXN2watPPoGFC22rpFUrm1Duusuu6a4Cxu5ju/ly05dM2TSF9YfWE2SCiK4cza11b6VXrV5si9uW7lonpxJOceBkGskgZYI4eYAjZ45cMvQ4SZHwIpQuUJrSBUpTpkAZ9hzfw7K9yxCEYBPMy21f5snWT2bp/eSoBOIrmkBUrvD77/Dii/DFF8n7rrsOBgywkxSrV3cuNnWZrUe2MmXTFKZsmsKOv3cQbIIRBBEhOCiY1hVbc951/mLSOH3+9GWvERIUcjEpJCWGlLelC5SmTMEylIosRUTopUsxp6xsHBYclvtbIL6iCUTlGqNGwbPP2vkjxkCRIvDPP/axqlWhUyebTNq2hYIFnY1VAbbw45oDa3jku0f4ee/PF/eXyF+COiXrXJoMkhJEQXtbLKIYQSb7fV9pDVPOCk0gaAJRuUhsLLRvb4cBJ1X+LVEC5s+H776zl7lOn7brlLRsaZNJx47QsKF2wjvMGy0Cf9MEgiYQlcsk1d1Ka+2Rc+dg2TKbUObPh3Xr7P6SJe38ko4d7W3Jkv6OWnHlLQJ/0wSCJhCVhx08aIs6JiWUOPcKC9dem9w6adnStmaUSkUTCJpAlALA5YJff01OJsuWwYULUKCALUeflFCqVXM6UhUgNIGgCUSpNJ04YftMkvpPdu60+6tVS04mbdvaxbJ0ud48SRMImkCUypSILamS1DpJ6owPDraPidg5KM8+C61bQ6lSdita1I4GU7mSJhA0gSiVZUmd8S+8AEsyWEg0NNR2yCcllFKlLv85aSteXBfUymF8kUBCvPliSqkAlC+fvXwVHp48bDg0FMaOtQUeDx+GQ4cu3zZtsrcJaRTeDgqyQ47TSi4pt717bV9Nhw62g1/lKppAlMoroqLsXJOs9IGIwPHjaSeYlNv27fb27Nm0X+f55yF/fnuZrEABuxUseGX3U482y2hItPIJTSBK5SVRUVn7ck2aIV+kCNTMZCFSETh1KjmpfPSRLdUiYl+nYUOoVQtOnrTHnToF+/cn30/a76nQ0ORkEhQEe/bY0WkhIfDYY9CzJ9SpYxOX8gntA1FK+UZaM+0zS14ul23FpEwyntxftQo2b7789YyxdcXq1bNb/fr2tmrVPNeHo30gSqmcIzuXzIKCIDLSblmROllNcYSDFwAACqlJREFUmGBbIhs2wMaN9nbmTNsaAoiIgLp1L08sJUpk9V36TwBeotMWiFIqd8jsC/bMGdiyJTmpJCWWI0eSjyld+vKkUru2HYDga0mXAI8fh2PH7G3StnYtvPuuLbyZL59nrblUtAWilFLpyax/J39+aNLEbikdOpScTJISy4cfQny8fTwoCGrUuDyxHDhgh0VHR0OLFvbSW9IXfuoE4MnPJ07YS3iZSUiwiTIAWiGaQJRSeVvSkOMOHZL3JSbayZgpk8qaNTBtWtqvERxsn5ORoCAoXNhuRYrY20qVLv059eNJ244d0Ldv8iW66Givvf0roZewlFLKU6dO2c76//s/u7pk0gizNm3gppvS/vJP2hcZeWUz/a+wD0RnoqMJRCkVALIzwsxh2geilFKBIDsjzHIhTSBKKZUdWZ2UmQvpuphKKaWyRROIUkqpbNEEopRSKls0gSillMoWTSBKKaWyRROIUkqpbMlxEwmNMUeA3U7H4WNXAXFOBxFg9DO5nH4ml9PPJG1XAZEi4tVywzkugeQFxpjV3p4xmtPpZ3I5/Uwup59J2nz1ueglLKWUUtmiCUQppVS2aAIJTGOcDiAA6WdyOf1MLqefSdp88rloH4hSSqls0RaIUkqpbNEEopRSKls0gfiJMWaXMWajMWadMWa1e18xY8wPxpjt7tui7v3GGPOeMWaHMWaDMaZRitcZ5D5+uzFmkFPvJ7uMMeOMMYeNMZtS7PPa52CMaez+nHe4n3sFS8D5RzqfyQvGmP3u35d1xpjOKR570v3+fjPGdEyxv5N73w5jzBMp9lcxxqxw759qjAnz37vLHmNMBWPMQmPMFmPMZmPMw+79efZ3JYPPxLnfFRHRzQ8bsAu4KtW+N4An3PefAP7Pfb8z8C1ggBbACvf+YsCf7tui7vtFnX5vWfwc2gCNgE2++ByAle5jjfu5Nzn9nrP5mbwAjEzj2NrAeiAfUAX4Awh2b38AVYEw9zG13c/5Cujvvv8x8KDT79mDz6QM0Mh9vyDwu/u959nflQw+E8d+V7QF4qybgQnu+xOAHin2TxRrOVDEGFMG6Aj8ICJ/i8g/wA9AJ38HfSVEZAnwd6rdXvkc3I8VEpHlYv8FTEzxWgErnc8kPTcDX4rIORHZCewAmrm3HSLyp4gkAF8CN7v/qm4HTHc/P+XnG7BE5ICIrHXfPwlsBcqRh39XMvhM0uPz3xVNIP4jwPfGmDXGmMHufaVE5ID7/kGglPt+OWBviufuc+9Lb39O563PoZz7fur9OdW/3JdjxiVdqiHrn0lx4JiIXEi1P8cwxlQGrgVWoL8rwGWfCTj0u6IJxH9aiUgj4CZgqDGmTcoH3X8F5fkx1fo5XPQRUA1oCBwA3nI2HGcYYwoAM4DhInIi5WN59Xcljc/Esd8VTSB+IiL73beHgZnYZuQhd1Ma9+1h9+H7gQopnl7evS+9/Tmdtz6H/e77qffnOCJySEQSRcQFfIr9fYGsfyZHsZdzQlLtD3jGmFDsF+VkEYlx787TvytpfSZO/q5oAvEDY0ykMaZg0n3gRmATMBtIGhUyCPjafX82MNA9sqQFcNzdbJ8P3GiMKepupt7o3pfTeeVzcD92whjTwn09d2CK18pRkr4k3Xpif1/Afib9jTH5jDFVgKuxncGrgKvdo2jCgP7AbPdf6QuBPu7np/x8A5b7/99nwFYReTvFQ3n2dyW9z8TR3xWnRxbkhQ072mG9e9sMPO3eXxxYAGwHfgSKufcb4APsSImNQJMUr3U3tjNsB3CX0+8tG5/FFGwz+zz2Gus93vwcgCbuf0B/AO/jrrYQyFs6n8kk93ve4P4iKJPi+Kfd7+83Uowcwo5E+t392NOpfv9Wuj+raUA+p9+zB59JK+zlqQ3AOvfWOS//rmTwmTj2u6KlTJRSSmWLXsJSSimVLZpAlFJKZYsmEKWUUtmiCUQppVS2aAJRSimVLZpAVMAzxiwyxjTxw3mGGWO2GmMmp9p/g7sEzUb3bbsUj6VZ0dVko2psqnMuy+Z76GGMqZ2d5yqVVZpAVK6WYlatJ4YAN4jIban2xwHdRKQednLVpBSPfQTch52kdTXJxS2fABaIyNXYeQtJJbNvSnHsYPfzLyMiLbMQd0o9sFVYlfI5TSDq/9s7uxCrqiiO//5R5Mw4NYwWRBLCFERFKkaCWAjVU6BGSg99MCGByQg5FD3lSxITCr0KGs1LFFomNZlkWWRjasl8OIZR5jxIElE0qGEwuXpY6zZnLtd7597EaFw/OJy19z57n302l7PO2vvutS4JkubG1/tWeayCjyU1Rdk/FoSk2ZJGQ+6UtCu+0EcldUnqljQg6aCk9sItnpTHOhiRdG/UbwnncYejzvJCu+9L2oe/vMv72h3tjEh6LvK24JuoPpK0vni9mQ2Y2U+RPAY0xe7eah5d6/UaW97Hs3FeGuP3jqTjkt4sWDk98tgQw5I2S1oMLAM2xVh1SHpG0teShiS9K6k56vaGJXRA0o+SVhbu/WJYVUOSeiKvQ9KesMD2S7o98lfFOA5J+qLijyOZvvzXuyvzmB4HMBcYB+ZHejvwRMifEzuDgdnAaMid+I7XVuAGYAxYE2Wv4c7iSvW3hnw/ETcDeKVwjzZ8Z21LtHuK2KVc1s+F+K7dFmAmrhAWRNkoZTFbKtRfCXwS8j0lOdL3AX0h/17IVykN9OGONUtln1LYNV3IPxvnpTEuc/APvq/wHcmz8N3Fpc3AbXHuBVYW2plVkDcC6wrX7Yg278Dde4NbSAeA5ki3F/p5W8iLgH0hHwVuLvYhjyvnqMe8T5JanDSzwZCP4EqlFp+ZxzY4I2kM+CDyjwJ3F657Czx2hqTrJLXhfo2WSXo+rpkB3BLyXjOrFGNjCfCemZ0DkLQTf/EP1OqopDuBV+O+U8bMTNK/cflw2MxORR8G8XE9CJwHXpfUhyumStwlaSOuYGcy2XfaLnMHfN9KKrlFfxB4w8z+iL7/Jvf+uhjYoYmgfdfGuR/olbQd2ElyRZEKJLmU/FmQ/wKaQh5nYrp0RpU6FwrpC0z+fZa/gA3/sn/UzL4rFkhaBJyrq+c1kDQH96L8lJmdiOxqHl1/lnSTmZ3W1LzGVqN8XK82s/GYynsAt4q68GBA5fQCK8xsSFInbtFUardaONercAtqfnmBma2J8X4YOCJpoZn9WuN5kmlCroEkl4NRfOoIJjx91stjAJKW4J5Wx/Cv6XWFNYEFU2hnP7BCUrPcM/IjkXdRwtr5EA+l2l/Kt+oeXev1GlsXYRVcb2a7gfXAvCg6g08JlmgFTsvdgJf/OaASe4GnC2sl7eYxJ05KWhV5kjQv5A4zO2RmG4BfmKwck2lOKpDkcrAZeFbSAL4G0gjno/4W3FstwMvANcCwpGORrop5SNBe3OPoIWCbmdWavuoCbgU2xOL0oKQbo2wtsA1fyzmBx9YG6AEekvQ9Pi3UE/m78bjcP+CxG9bW6vNFaAX6JA0DXwLdkf828EL8qaADeCmesx84XqtRM9uDK7lvYrqsND34OLBaUsmj9PLI3xQL7iP42slQg8+T/A9Jb7xJkiRJQ6QFkiRJkjREKpAkSZKkIVKBJEmSJA2RCiRJkiRpiFQgSZIkSUOkAkmSJEkaIhVIkiRJ0hB/A7xvmjO0t4FOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3GggA1z_3NQ",
        "colab_type": "text"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BonEyZvd_78n",
        "colab_type": "code",
        "outputId": "f6fadd13-da4c-4bb5-e0c2-4bc8590b4cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def run_model(dataloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # no_grad() set the require_grad flag to false temporarily, so the gradient will not be updated???\n",
        "  with torch.no_grad():\n",
        "    # iterate through batchs\n",
        "      for data in dataloader:\n",
        "          # data is a tuple (images, labels)\n",
        "          images, labels = data\n",
        "          # calculate the output from the image inputs in the batch\n",
        "          # return value is tensor\n",
        "          outputs = net(images)\n",
        "          # get the prediected labels from the outputs.data\n",
        "          # use max(input=outputs.data, dim=1), it outputs a named tuple (value, indices)\n",
        "          # the result is the max value in each row and its index\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  return correct, total\n",
        "\n",
        "correct_train, total_train = run_model(trainloader)\n",
        "print('Accuracy of the network on the 50000 train images: %d %%' % (\n",
        "    100 * correct_train / total_train))\n",
        "\n",
        "correct_test, total_test = run_model(testloader)\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct_test / total_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 50000 train images: 68 %\n",
            "Accuracy of the network on the 10000 test images: 63 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}